---
title:          "GaitWay: Gait Data-Based VR Locomotion Prediction System Robust to Visual Distraction"
date:           11 May 2024
selected:       true
pub:            "CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">1<sup>st</sup> author</span>'
pub_vol:        "No.173 "
pub_date:       "11. May. 2024. "
pub_pp:         "1-8."

abstract: >-
  In VR environments, user’s sense of presence is enhanced through natural locomotion. Redirected Walking (RDW) technology can provide a wider walking area by manipulating the trajectory of the user. Considering that the user’s future position enables a broader application of RDW, research has utilized gaze data combined with past positions to reduce prediction errors. However, in VR content that are replete with creatures and decorations, gaze dispersion may deteriorate the data quality. Thus, we propose an alternative system that utilizes gait data, GaitWay, which correlates directly to user locomotion. This study involved 11 participants navigating a visually distracting three-tiered VR environment while performing designated tasks. We employed a long short-term memory network for GaitWay to forecast positions two seconds ahead and evaluated the prediction accuracy. The findings demonstrated that incorporating gaze data significantly increased errors in highly-distracted settings, whereas GaitWay consistently reduced errors, regardless of the environmental complexity.
cover: /assets/images/covers/GaitWay.png
authors:
  - Seokhyun Hwang
  - YongIn Kim
  - <strong>Jeongseok Oh</strong>
  - SeungJun Kim
links:
  DOI: https://doi.org/10.1145/3613905.3651073
  PDF: /assets/paper/gaitway.pdf
---
